\newif\ifonecolumn % Boolean to keep track of column mode (can use to format formulas etc)
%\documentclass{IEEEtran}\onecolumnfalse
%\documentclass[12pm,draftcls,onecolumn]{IEEEtran}\onecolumntrue

% ------------------------------------------------------------------------------
%   New IEEE Transactions Color Template
\documentclass[journal,twoside,web]{ieeecolor}\onecolumnfalse
% \documentclass[journal,twoside,web,onecolumn]{ieeecolor}\onecolumntrue
\usepackage{generic}
% \usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
% \def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%     T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
% \markboth{\journalname, VOL. XX, NO. XX, XXXX 2018}
% {Author \MakeLowercase{\textit{et al.}}: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS (February 2017)}
% ------------------------------------------------------------------------------

\pdfoutput=1
\pdfminorversion = 4

      
\input{macros.tex}

\title{\LARGE \bf
A Minimum Discounted Reward Hamilton-Jacobi Formulation for Computing Reachable Sets 
}
\author{
Anayo K. Akametalu \and Shromona Ghosh \and Jaime F. Fisac \and Claire J. Tomlin
\thanks{
 Department of Electrical Engineering and Computer Sciences, 
        University of California, Berkeley , United States.\newline
        {\tt\small \{kakametalu, shromona.ghosh, jfisac, tomlin\}~@eecs.berkeley.edu }}% 
\thanks{
This work is supported by NSF under the CPS FORCES and VehiCal projects, by the UC-Philippine-California Advanced Research Institute, and by the ONR MURI Embedded Humans. The research of A.K. Akametalu has received funding from the National GEM Consortium Fellowship.} 
}
%TODO: Do we want to reincorporate the 
%
\begin{document}
\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
We propose a novel formulation for approximating reachable sets via solving a minimum discounted reward optimal control problem. The formulation yields a continuous solution that can be obtained by solving a Hamilton-Jacobi equation. Furthermore, the numerical approximation to this solution can be obtained as the unique fixed-point to a contraction mapping. This allows for more efficient solution methods that could not be applied under traditional formulations. In addition, this formulation provides a link between reinforcement learning and learning reachable sets for systems with unknown dynamics, allowing algorithms from the former to be applied to the latter. We use two benchmarks, double integrator, and pursuit-evasion games, to show the correctness of the formulation as well as its strengths in comparison to previous work.
\end{abstract}


\section{Introduction \label{sec:intro}}
\input{introduction}

\section{Background \label{sec:back}} 
\input{background}

\section{Minimum of Discounted Rewards \label{sec:mdr}}
\input{discounting}

\section{Improving Convergence \label{sec:conv}}
\input{converge}

\section{Learning Reachable Sets \label{sec:learn}}
\input{learning}

\section{Simulations \label{sec:sim}}
\input{simulations.tex}

\section{Conclusions and Future Work \label{sec:end}}
\input{conclusions}





\printbibliography
\end{document}
